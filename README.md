# Google-trends

## Introduction   

This project consists on an ETL (Extract, Transform, Load) process.  
- Extract: download data from Google Trends.  
- Transform: keep important columns, append data for each month/year.  
- Load: upload files to Dropbox in chunks of 5GB.  

## Files and scripts
- main.py: Main script to import,process and load the data.
- config.py: Defines configuration object that contains all values configured in the config.properties file.
- dropbox_handler.py: Contains the code to download/upload files to Dropbox.  It uses the library ``dropbox``.
- files_manager.py: Contains the code to manage files and divide them into chunks.
- process.py: Includes the code for transforming the downloaded files into files of the certain 
size (threshold configured).
- gtrends.py: Includes the code for stabilising the connection with Google Trends. 
It is used the library ``pytrends``.
- config.properties: Configuration file. 
- requirements.txt: Requirements for running the environment.   

### Extract
 For the extraction step, csv files are imported from Google Trends, saving them locally in two directories.
 One directory for monthly files and another for daily files. 
 A pseudo-code is provided to understand how the files are downloaded.   
```python
	for ticker in ticker:
		for category in categories:
			if (category_type=='monthly'):
				download_monthly(year_from, year_to, ticker, category)
			else:
				download_daily(year_from, year_to, ticker, category)
```
  
In summary, for each ticker,category and category type the data is downloaded for the configured frame composed 
by year_from and year_to.   

 **Observations:**    
1. *Clean data:* In order to clean the data, a transformation is used in this script, keeping only the columns of interest. 
 In addition, the date format is transformed from 'Y-M-d' to 'Y-M' in the case of monthly files.   
     
2. *Handle errors:* As Google trends has a limit for the amount of files that can be downloaded per day, which is not fixed. 
In case that the file could not be downloaded an error message would appear in the log and the excecution would be stopped. Next time that the script is executed 
it would perform another attempt for this file. 
In order to check if the file should be downloaded or not, it is checked if the file is already in the local folder, 
in that case it is not downloaded. The script output indicates if there are more files to download. In the case that all 
the files have been downloaded, the output would look as follows:     
```bash
download_all=True 
```
Otherwise, it would be:    
```bash
download_all=False
```

#### Execution: 

```bash
python main.py -c 'config.properties' --import=true
```


### Transform
For reasons of optimization, the transformation is done during the extraction and loading steps. 
In the extraction is used to clean the data and in the loading to append the content of the files into one. 

### Load
The loading step consist on reading the local files for monthly and daily data and generate 2 different types of files. One that contains 
the information for all the months and other type for all the days. The information is appended into one file until reaching 
the threshold configured in ``output_size_mb``.    
Once the threshold is reached, the file is uploaded to Dropbox, and start to generate a new file. 
This process is repeated until all the files have been processed.  

**Observations**
1. *Transformation:* The appended information is sorted by date before uploading the file the information.    
2. *Handle errors:* In case that the upload to Dropbox fails, the result file would be saved in the results directory. 
These files should be uploaded manually to dropbox. 


#### Execution: 

```bash
python main.py -c 'config.properties' --process=true
```

## Configuration:
**Log Configuration**  
- log_level: Log level (INFO, WARNING, ERROR)

**Dropbox Configuration**     
- *access_token:* Access token generated by Dropbox to access/upload files.  
- *dropbox_timeout:* Timeout for HTTP connection by the Dropbox API.  
- *dropbox_chunck:* Chunk size to send data to Dropbox.  
- *tickers_path:* Path in Dropbox where the tickers file is located.  
- *dropbox_folder_upload:* Path for upload result files.  
- *tickers_folder:* Local folder's path where ticker file is stored.  
- *data_folder_monthly:* Local folder's path for monthly data.  
- *data_folder_daily:* Local folder's path for daily data.  
- *result_folder:* Local folder's path for results files.
Files are saved temporary in this folder before uploading to Dropbox. 

**Google Trends Configuration**    
- *encoding:* Encoding used for download the data.  
- *tz:* Timezone for download data.  
- *categories:* List of categories to download. With its' correspond type (monthly/daily).   
The format should be like: category_number:category_type,category_number:category_type. 
Example: 1283:monthly,107:monthly,107:daily,278:monthly,278:daily  
- *year_from:* Year from which the data should be downloaded.  
- *year_until:* Year until which the data should be downloaded.  
- *geo:* Indicates geographical area from the data. In the case to want all areas, this field should be empty.  
- *gtrends_timeout_connect:* Timeout for opening HTTP connection with Google Trends.   
- *gtrends_timeout_read:* Timeout for HTTP connection for reading the data to download.  
- *retries:* Indicates how many times should retry when the connection fails.   
- *backoff_factor:* Seconds between attempts after the second retry.  
- *output_size_mb:* Threshold in MB for the files to be uploaded.  
- *prefix:* Prefix for the result files.  

























